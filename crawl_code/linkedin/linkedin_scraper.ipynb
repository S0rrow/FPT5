{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobspy import scrape_jobs\n",
    "from utils import Logger\n",
    "import time, os\n",
    "job_titles = [\n",
    "    \"Software Engineer\",\n",
    "    \"Data Scientist\",\n",
    "    \"Systems Administrator\",\n",
    "    \"Database Administrator\",\n",
    "    \"Network Engineer\",\n",
    "    \"Cybersecurity Analyst\",\n",
    "    \"IT Project Manager\",\n",
    "    \"DevOps Engineer\",\n",
    "    \"UX UI Designer\",\n",
    "    \"Cloud Engineer\",\n",
    "    \"Technical Support Specialist\",\n",
    "    \"Business Intelligence Analyst\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_it_jobs(logger, site_name, search_term, location, results_wanted, hours_old):\n",
    "    try:\n",
    "        jobs = scrape_jobs(\n",
    "            site_name=[site_name],\n",
    "            search_term=search_term,\n",
    "            location=location,\n",
    "            results_wanted=results_wanted,\n",
    "            hours_old=hours_old,  # (only Linkedin/Indeed is hour specific, others round up to days old)\n",
    "            country_indeed=location,  # only needed for indeed / glassdoor\n",
    "            # linkedin_fetch_description=True  # get full description and direct job url for linkedin (slower)\n",
    "            # proxies=[\"208.195.175.46:65095\", \"208.195.175.45:65095\", \"localhost\"],\n",
    "        )\n",
    "        logger.log(f\"Found {len(jobs)} jobs\", 4)\n",
    "    except Exception as e:\n",
    "        logger.log(f\"Error during scrape jobs: {e}\", 1)\n",
    "    try:\n",
    "        # Dynamically create the CSV filename\n",
    "        curdate = time.strftime(\"%Y%m%d\")\n",
    "        resultpath = \"./downloaded_files\"\n",
    "        if not os.path.isdir(resultpath):\n",
    "            os.mkdir(resultpath)\n",
    "        filename = f\"{resultpath}/{site_name}_{search_term.replace(' ', '_')}_{location.replace(' ', '_')}_{curdate}.json\"\n",
    "        jobs.to_json(filename, orient='records', force_ascii=False)\n",
    "        logger.log(f\"CSV saved as {filename}\", 4)\n",
    "    except Exception as e:\n",
    "        logger.log(f\"Error during jsonizing results: {e}\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 16:53:26,659 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:53:30,428 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:53:34,907 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-08-12 16:53:41,943 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-08-12 16:53:45,574 - JobSpy - INFO - LinkedIn search page: 5\n",
      "2024-08-12 16:53:45,972 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:53:51,056 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:53:56,141 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:53:59,811 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-08-12 16:54:06,447 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-08-12 16:54:12,277 - JobSpy - INFO - LinkedIn search page: 5\n",
      "2024-08-12 16:54:13,131 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:54:18,224 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:54:21,878 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:54:22,484 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:54:27,512 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:54:31,605 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:54:39,591 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-08-12 16:54:46,347 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-08-12 16:54:51,639 - JobSpy - INFO - LinkedIn search page: 5\n",
      "2024-08-12 16:54:51,969 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:54:57,046 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:55:02,863 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:55:10,208 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-08-12 16:55:14,870 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-08-12 16:55:15,334 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:55:20,394 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:55:27,938 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:55:28,274 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:55:33,293 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:55:38,519 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:55:38,935 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:55:43,965 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:55:50,118 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:55:50,441 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:55:55,478 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:56:00,892 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:56:01,242 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:56:06,277 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:56:11,294 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:56:17,459 - JobSpy - INFO - LinkedIn search page: 3\n",
      "2024-08-12 16:56:23,900 - JobSpy - INFO - LinkedIn search page: 4\n",
      "2024-08-12 16:56:24,232 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:56:29,297 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:56:34,788 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:56:35,130 - JobSpy - INFO - Linkedin finished scraping\n",
      "2024-08-12 16:56:40,156 - JobSpy - INFO - LinkedIn search page: 1\n",
      "2024-08-12 16:56:46,108 - JobSpy - INFO - LinkedIn search page: 2\n",
      "2024-08-12 16:56:46,580 - JobSpy - INFO - Linkedin finished scraping\n"
     ]
    }
   ],
   "source": [
    "logger = Logger()\n",
    "site_name = \"linkedin\"\n",
    "location = \"South Korea\"\n",
    "results_wanted = 100\n",
    "hours_old = 72\n",
    "for job_title in job_titles:\n",
    "    logger.log(f\"scraping for {job_title}...\", 4)\n",
    "    scrape_it_jobs(\n",
    "        logger=logger,\n",
    "        site_name=site_name,\n",
    "        search_term=job_title,\n",
    "        location=location,\n",
    "        results_wanted=results_wanted,\n",
    "        hours_old=hours_old\n",
    "    )\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
