{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rocketpunch crawler\n",
    "def rocketpunch_crawler(url, headers):\n",
    "    session = requests.Session()\n",
    "    res = session.get(url.format(1), headers=headers)\n",
    "    res = json.loads(res.text)\n",
    "    soup = BS(res['data']['template'], 'html.parser')\n",
    "\n",
    "    page_size = soup.find('div', {'class': 'tablet computer large screen widescreen only'}).find_all('a', {'class': 'item'})[-1].text.strip()\n",
    "\n",
    "    data_list = parse_page(soup)\n",
    "\n",
    "    for i in range(2, int(page_size) + 1):\n",
    "        res = session.get(url.format(i), headers=headers)\n",
    "        res = json.loads(res.text)\n",
    "        soup = BS(res['data']['template'], 'html.parser')\n",
    "        data_list.extend(parse_page(soup))\n",
    "        time.sleep(2) # for sake of politeness\n",
    "\n",
    "    return data_list\n",
    "\n",
    "# API 호출\n",
    "# company_id, company_name, job_id, description, job_title, job_career\n",
    "def parse_page(soup):\n",
    "    data_list = []\n",
    "    for company in soup.find_all('div', {'class': 'company item'}):\n",
    "        company_data = {}\n",
    "        company_data['company_id'] = company['data-company_id']\n",
    "        for content in company.find_all('div', {'class': 'content'}):\n",
    "            company_data['company_name'] = content.find('a', {'class': 'company-name nowrap header name'}).text.strip()\n",
    "            company_data['description'] = content.find('div', {'class': 'description'}).text.strip()\n",
    "            \n",
    "            for job_detail in content.find_all('div', {'class': 'job-detail'}):\n",
    "                job_data = company_data.copy()\n",
    "                job_data['job_id'] = job_detail.find('a', {'class': 'nowrap job-title'})['href'].split('/')[2]\n",
    "                job_data['job_title'] = job_detail.find('a', {'class': 'nowrap job-title'}).text.strip()\n",
    "                job_data['job_career'] = job_detail.find('div', {'class': 'job-stat-info'}).text.strip().split(' / ')\n",
    "                job_data['timestamp'] = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "                job_data['crawl_domain'] = 'www.rocketpunch.com'\n",
    "                data_list.append(job_data)\n",
    "                \n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 공고 크롤링\n",
    "# job_task, job_detail, job_industry, job_specialties, date_start, date_end, timestamp\n",
    "def parse_job_page(data, headers):\n",
    "    job_url = 'https://www.rocketpunch.com/jobs/{}'\n",
    "    session = requests.Session()\n",
    "    pattern = re.compile('[ㄱ-ㅎ가-힣]+')\n",
    "\n",
    "    for job in data:\n",
    "        res = session.get(job_url.format(job['job_id']), headers=headers)\n",
    "        soup = BS(res.text, 'html.parser')\n",
    "        \n",
    "        # 주요 업무(업무 내용) : job_task\n",
    "        job_task_div = soup.find('div', class_='duty break')\n",
    "        \n",
    "        task_span_hidden = job_task_div.find('span', class_='hide full-text')\n",
    "        task_span_short = job_task_div.find('span', class_='short-text') if not task_span_hidden else None\n",
    "        task_span = task_span_hidden.text if task_span_hidden else (task_span_short.text if task_span_short else \"\")\n",
    "        job['job_task'] = task_span.strip() if task_span else \"\"\n",
    "        \n",
    "        # 업무 기술/활동분야 : job_specialties\n",
    "        specialties_raw = soup.find('div', class_='job-specialties')\n",
    "        specialties = [a.text for a in specialties_raw.find_all('a')]\n",
    "        job['job_specialties'] = ', '.join(specialties)\n",
    "        \n",
    "        # 채용 상세 : job_detail\n",
    "        detail_div = soup.find('div', class_='content break')\n",
    "        detail_span_hidden = detail_div.find('span', class_='hide full-text')\n",
    "        detail_span_short = detail_div.find('span', class_='short-text') if not detail_span_hidden else None\n",
    "        detail_span = detail_span_hidden.text if detail_span_hidden else detail_span_short.text\n",
    "        job['job_detail'] = detail_span.strip() if detail_span else \"\"\n",
    "        \n",
    "        # 산업 분야 : job_industry\n",
    "        industry_div = soup.find('div', class_='job-company-areas')\n",
    "        industry_text = [a.text for a in industry_div.find_all('a')]\n",
    "        job['job_industry'] = ', '.join(industry_text)\n",
    "        \n",
    "        # 채용 시작일/만료일 : date_start, date_end\n",
    "        job_date = soup.find('div', class_='job-dates')\n",
    "        date_span = job_date.find_all('span')\n",
    "        \n",
    "        #수시채용, 상시채용 예외처리\n",
    "        if any(pattern.search(span.text) for span in date_span):\n",
    "            job['date_start'] = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "            job['date_end'] = None\n",
    "            \n",
    "        else:\n",
    "            if len(date_span) > 1:\n",
    "                job['date_start'] = datetime.datetime.strptime(date_span[0].text.strip(), '%Y.%m.%d').date()\n",
    "                job['date_end'] = datetime.datetime.strptime(date_span[1].text.strip(), '%Y.%m.%d').date()\n",
    "            elif len(date_span) == 1:\n",
    "                job['date_start'] = datetime.datetime.strptime(date_span[0].text.strip(), '%Y.%m.%d').date()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_span_short' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.rocketpunch.com/api/jobs/template?page=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#data_list = rocketpunch_crawler(url, headers)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m detailed_data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_job_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m, in \u001b[0;36mparse_job_page\u001b[0;34m(data, headers)\u001b[0m\n\u001b[1;32m     13\u001b[0m job_task_div \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduty break\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m task_span_hidden \u001b[38;5;241m=\u001b[39m job_task_div\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhide full-text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m task_span \u001b[38;5;241m=\u001b[39m task_span_hidden\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m task_span_hidden \u001b[38;5;28;01melse\u001b[39;00m (task_span_short\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtask_span_short\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m job[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_task\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m task_span\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m task_span \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 업무 기술/활동분야 : job_specialties\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_span_short' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'\n",
    "    }\n",
    "    url = 'https://www.rocketpunch.com/api/jobs/template?page={}'\n",
    "    #data_list = rocketpunch_crawler(url, headers)\n",
    "    detailed_data = parse_job_page(data_list, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "test = '상시채용'\n",
    "pattern = re.compile('[ㄱ-ㅎ가-힣]+')\n",
    "if pattern.search(test):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocketpunch_list = rocketpunch_crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocketpunch_list.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(rocketpunch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>description</th>\n",
       "      <th>job_list</th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_info</th>\n",
       "      <th>job_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6532</td>\n",
       "      <td>마카롱팩토리</td>\n",
       "      <td>대한민국 1등 운전자 차량관리 필수앱 - 마이클</td>\n",
       "      <td>[{'company_id': '6532', 'company_name': '마카롱팩토...</td>\n",
       "      <td>151375</td>\n",
       "      <td>프론트엔드 개발 (5년 이상)</td>\n",
       "      <td>[경력]</td>\n",
       "      <td>09/30 마감</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6311</td>\n",
       "      <td>다날</td>\n",
       "      <td>데이터베이스 및 온라인정보 제공업체</td>\n",
       "      <td>[{'company_id': '6311', 'company_name': '다날', ...</td>\n",
       "      <td>151201</td>\n",
       "      <td>다날 테스트 자동화 개발 담당 경력 채용</td>\n",
       "      <td>[경력]</td>\n",
       "      <td>09/29 마감</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160928</td>\n",
       "      <td>에이치디메디</td>\n",
       "      <td>쉽고 편한 의료 서비스 i약</td>\n",
       "      <td>[{'company_id': '160928', 'company_name': '에이치...</td>\n",
       "      <td>151453</td>\n",
       "      <td>i약 SaaS 서버 엔지니어(Java/SpringBoot)</td>\n",
       "      <td>[5,000 - 8,000만원, 0.5% - 3.0%, 경력]</td>\n",
       "      <td>08/29 마감</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_id company_name                 description  \\\n",
       "0       6532       마카롱팩토리  대한민국 1등 운전자 차량관리 필수앱 - 마이클   \n",
       "1       6311           다날         데이터베이스 및 온라인정보 제공업체   \n",
       "2     160928       에이치디메디             쉽고 편한 의료 서비스 i약   \n",
       "\n",
       "                                            job_list  job_id  \\\n",
       "0  [{'company_id': '6532', 'company_name': '마카롱팩토...  151375   \n",
       "1  [{'company_id': '6311', 'company_name': '다날', ...  151201   \n",
       "2  [{'company_id': '160928', 'company_name': '에이치...  151453   \n",
       "\n",
       "                          job_title                            job_info  \\\n",
       "0                  프론트엔드 개발 (5년 이상)                                [경력]   \n",
       "1            다날 테스트 자동화 개발 담당 경력 채용                                [경력]   \n",
       "2  i약 SaaS 서버 엔지니어(Java/SpringBoot)  [5,000 - 8,000만원, 0.5% - 3.0%, 경력]   \n",
       "\n",
       "   job_date  \n",
       "0  09/30 마감  \n",
       "1  09/29 마감  \n",
       "2  08/29 마감  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>description</th>\n",
       "      <th>job_list</th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_info</th>\n",
       "      <th>job_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>203363</td>\n",
       "      <td>제이제이앤컴퍼니스</td>\n",
       "      <td>인공지능과 공정제어 기반의 해양 엔지니어링 전문 기업</td>\n",
       "      <td>[{'company_id': '203363', 'company_name': '제이제...</td>\n",
       "      <td>151418</td>\n",
       "      <td>백엔드 엔지니어 정규직 채용 공고</td>\n",
       "      <td>[경력]</td>\n",
       "      <td>08/23 마감</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id company_name                    description  \\\n",
       "64     203363    제이제이앤컴퍼니스  인공지능과 공정제어 기반의 해양 엔지니어링 전문 기업   \n",
       "\n",
       "                                             job_list  job_id  \\\n",
       "64  [{'company_id': '203363', 'company_name': '제이제...  151418   \n",
       "\n",
       "             job_title job_info  job_date  \n",
       "64  백엔드 엔지니어 정규직 채용 공고     [경력]  08/23 마감  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유료광고와 겹치는지 확인용 -> 유료공고와 겹침으로 유료쪽 광고 크롤링x\n",
    "df.loc[df['company_name'].isin(['제이제이앤컴퍼니스'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공고 크롤링\n",
    "def parse_job_page():\n",
    "    job_url = 'https://www.rocketpunch.com/jobs/151267'\n",
    "    session = requests.Session()\n",
    "    #print(data['job_id'])\n",
    "    #res = session.get(job_url.format(data['job_id']), headers=headers)\n",
    "    res = session.get(job_url, headers=headers)\n",
    "    soup = BS(res.text, 'html.parser')\n",
    "    \n",
    "    div = soup.find('div', class_='duty break')\n",
    "    #print(div)\n",
    "    if div:\n",
    "      span_hidden = div.find('span', class_='hide full-text')\n",
    "      span_short = div.find('span', class_='short-text') if not span_hidden else None\n",
    "      span = span_hidden.text if span_hidden else span_short\n",
    "    print(span)\n",
    "    \n",
    "    job_date = soup.find('div', class_='job-dates')\n",
    "    date_span = job_date.find_all('span')\n",
    "    for i, date in enumerate(date_span):\n",
    "      text = date.get_text(strip=True)\n",
    "      date_only = text.split()[0]\n",
    "      \n",
    "      year = datetime.datetime.now().year\n",
    "      mon = date_only.split('/')[0]\n",
    "      day = date_only.split('/')[1]\n",
    "      \n",
    "      if i == 0 :\n",
    "        date_start = datetime.datetime.strptime(f'{year}-{mon}-{day}', '%Y-%m-%d').date()\n",
    "        print(date_start)\n",
    "      else:\n",
    "        date_end = datetime.datetime.strptime(f'{year}-{mon}-{day}', '%Y-%m-%d').date()\n",
    "        print(date_end)\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슬로그업의 개발 문화를 먼저 소개할게요.슬로거들은 ‘불확실한 가설과 위험은 마지막보다 초기에 대응한다’는 마음으로PM, 디자이너, 개발자 등 모든 구성원이 팀 단위로 프로덕트를 정의하고 설계해나가요.이중 백엔드 프로덕트 엔지니어는 다음과 같은 업무를 담당해요.- 프로젝트 목표와 기능별 목적에 관해 이해- 아이디어 단계부터 참여해 효율성 높고 창의적인 방향성 도출- 최소의 개발로 최대한 효과를 낼 수 있는 구조 고민- PM, PD와 협업해 단순 기능구현이 아닌 ‘문제 해결’을 목적으로 개발- 가설검증 단계에서 매우 빠른 속도로 프로토타입 구축- 기초검증된 목표를 효율적이고 확장성 있는 설계로 개발- 지속적 뉴테크 학습과 비지니스적 요소 고려로 유연하게 제품에 적용- 정기적 회고를 통해 부족한 점을 찾고 꾸준히 개선하며 지속 성장\n",
      "2024-08-31\n",
      "2024-07-31\n"
     ]
    }
   ],
   "source": [
    "parse_job_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-08-07'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
